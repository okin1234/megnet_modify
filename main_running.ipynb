{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f544953-548f-4d9a-99be-440c0dbf9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e254a1-b0af-48b9-a856-c647f0f85dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a41d74-6490-4573-a667-cfad9dc372f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"/home/rnwnsgud1234/4.BRL/12.MEGNET/Datasets/\"\n",
    "\n",
    "''' feature 종류 setting '''\n",
    "atom_features=['element', 'formal_charge', 'hybridization', 'donor', 'acceptor'] \n",
    "bond_features=['spatial_distance', 'same_ring', 'bond_type']\n",
    "global_features=['fedility']\n",
    "\n",
    "'''model setting'''\n",
    "nblocks=3\n",
    "global_embedding_dim=16\n",
    "npass=2\n",
    "\n",
    "''' data 개수 조절 '''\n",
    "num_xtb_data=None\n",
    "num_g09_data=None\n",
    "\n",
    "''' 데이트 load해서 쓸건지? '''\n",
    "load=False\n",
    "\n",
    "''' 데이터 관련 기타 setting '''\n",
    "random_state=1000\n",
    "g09_data_cut=None\n",
    "with_rdkit=True\n",
    "rdkit_rank=20\n",
    "to_class=False\n",
    "class_num=5\n",
    "cut_mode='qcut'\n",
    "onehot=True\n",
    "\n",
    "running = trainer(base_dir, atom_features, bond_features, global_features, nblocks, global_embedding_dim, npass, num_xtb_data, num_g09_data, load, random_state, g09_data_cut, with_rdkit, rdkit_rank, to_class, cut_mode, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc1152d-4986-4b57-ab0e-a736bd57a560",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g09 datas convert to graph datas~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 502/502 [00:01<00:00, 397.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g09 datas convert to graph datas~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 467/467 [00:00<00:00, 4392.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtb datas conver to graph datas~~ (it may be doing for few minutes...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 123259/123259 [00:27<00:00, 4498.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of g09_datas is 467\n",
      "The length of g09_targets is 467\n",
      "xtb datas conver to graph datas~~ (it may be doing for few minutes...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134239/134239 [12:10<00:00, 183.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of xtb_datas is 119965\n",
      "The length of xtb_targets is 119965\n",
      "Train, val data sizes are  120339 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mihateml\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rnwnsgud1234/4.BRL/12.MEGNET/MEGNET/megnet_custom/wandb/run-20220422_152818-3vbj62xz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ihateml/MEGNET_feature_test/runs/3vbj62xz\" target=\"_blank\">smart-donkey-57</a></strong> to <a href=\"https://wandb.ai/ihateml/MEGNET_feature_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
      "2022-04-22 15:28:40.655977: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-22 15:28:41.520189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5652 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:81:00.0, compute capability: 7.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to log validation data. When using a generator for validation_data, you must pass validation_steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00001: val_mae improved from inf to 0.39141, saving model to callback/val_mae_00001_0.391408.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 96s - loss: 0.1289 - mae: 0.2397 - val_loss: 0.2720 - val_mae: 0.3914 - _timestamp: 1650609054.0000 - _runtime: 155.0000 - 96s/epoch - 102ms/step\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00002: val_mae improved from 0.39141 to 0.30001, saving model to callback/val_mae_00002_0.300008.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 73s - loss: 0.0654 - mae: 0.1858 - val_loss: 0.1648 - val_mae: 0.3000 - _timestamp: 1650609130.0000 - _runtime: 231.0000 - 73s/epoch - 78ms/step\n",
      "Epoch 3/200\n",
      "941/941 - 73s - loss: 0.0578 - mae: 0.1735 - val_loss: 0.1823 - val_mae: 0.3017 - _timestamp: 1650609204.0000 - _runtime: 305.0000 - 73s/epoch - 78ms/step\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00004: val_mae improved from 0.30001 to 0.24318, saving model to callback/val_mae_00004_0.243178.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0529 - mae: 0.1644 - val_loss: 0.1175 - val_mae: 0.2432 - _timestamp: 1650609278.0000 - _runtime: 379.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00005: val_mae improved from 0.24318 to 0.24172, saving model to callback/val_mae_00005_0.241720.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 74s - loss: 0.0474 - mae: 0.1549 - val_loss: 0.1218 - val_mae: 0.2417 - _timestamp: 1650609352.0000 - _runtime: 453.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 6/200\n",
      "941/941 - 74s - loss: 0.0429 - mae: 0.1463 - val_loss: 0.1719 - val_mae: 0.2702 - _timestamp: 1650609426.0000 - _runtime: 527.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00007: val_mae improved from 0.24172 to 0.24084, saving model to callback/val_mae_00007_0.240837.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 74s - loss: 0.0395 - mae: 0.1400 - val_loss: 0.1215 - val_mae: 0.2408 - _timestamp: 1650609500.0000 - _runtime: 601.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00008: val_mae improved from 0.24084 to 0.23490, saving model to callback/val_mae_00008_0.234897.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 74s - loss: 0.0365 - mae: 0.1340 - val_loss: 0.1012 - val_mae: 0.2349 - _timestamp: 1650609575.0000 - _runtime: 676.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00009: val_mae improved from 0.23490 to 0.23327, saving model to callback/val_mae_00009_0.233267.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0340 - mae: 0.1292 - val_loss: 0.1012 - val_mae: 0.2333 - _timestamp: 1650609649.0000 - _runtime: 750.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00010: val_mae improved from 0.23327 to 0.21530, saving model to callback/val_mae_00010_0.215303.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0320 - mae: 0.1243 - val_loss: 0.1016 - val_mae: 0.2153 - _timestamp: 1650609724.0000 - _runtime: 825.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00011: val_mae improved from 0.21530 to 0.21315, saving model to callback/val_mae_00011_0.213151.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0316 - mae: 0.1218 - val_loss: 0.0983 - val_mae: 0.2132 - _timestamp: 1650609799.0000 - _runtime: 900.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00012: val_mae improved from 0.21315 to 0.21119, saving model to callback/val_mae_00012_0.211185.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0287 - mae: 0.1175 - val_loss: 0.1211 - val_mae: 0.2112 - _timestamp: 1650609874.0000 - _runtime: 975.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 13/200\n",
      "941/941 - 74s - loss: 0.0320 - mae: 0.1248 - val_loss: 0.1134 - val_mae: 0.2341 - _timestamp: 1650609948.0000 - _runtime: 1049.0000 - 74s/epoch - 78ms/step\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00014: val_mae improved from 0.21119 to 0.20605, saving model to callback/val_mae_00014_0.206050.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0267 - mae: 0.1138 - val_loss: 0.0847 - val_mae: 0.2061 - _timestamp: 1650610023.0000 - _runtime: 1124.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 15/200\n",
      "941/941 - 75s - loss: 0.0262 - mae: 0.1118 - val_loss: 0.1096 - val_mae: 0.2111 - _timestamp: 1650610098.0000 - _runtime: 1199.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 16/200\n",
      "941/941 - 73s - loss: 0.0253 - mae: 0.1095 - val_loss: 0.0989 - val_mae: 0.2313 - _timestamp: 1650610171.0000 - _runtime: 1272.0000 - 73s/epoch - 78ms/step\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00017: val_mae improved from 0.20605 to 0.20577, saving model to callback/val_mae_00017_0.205773.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 74s - loss: 0.0241 - mae: 0.1071 - val_loss: 0.0923 - val_mae: 0.2058 - _timestamp: 1650610245.0000 - _runtime: 1346.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 18/200\n",
      "941/941 - 74s - loss: 0.0252 - mae: 0.1099 - val_loss: 0.1301 - val_mae: 0.2403 - _timestamp: 1650610320.0000 - _runtime: 1421.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00019: val_mae improved from 0.20577 to 0.20144, saving model to callback/val_mae_00019_0.201437.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0232 - mae: 0.1043 - val_loss: 0.0933 - val_mae: 0.2014 - _timestamp: 1650610394.0000 - _runtime: 1495.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 20/200\n",
      "941/941 - 74s - loss: 0.0218 - mae: 0.1023 - val_loss: 0.0844 - val_mae: 0.2055 - _timestamp: 1650610469.0000 - _runtime: 1570.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 21/200\n",
      "941/941 - 74s - loss: 0.0331 - mae: 0.1146 - val_loss: 0.1315 - val_mae: 0.2443 - _timestamp: 1650610543.0000 - _runtime: 1644.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 22/200\n",
      "941/941 - 75s - loss: 0.0221 - mae: 0.1022 - val_loss: 0.0976 - val_mae: 0.2081 - _timestamp: 1650610618.0000 - _runtime: 1719.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 23/200\n",
      "941/941 - 74s - loss: 0.0207 - mae: 0.0993 - val_loss: 0.1226 - val_mae: 0.2189 - _timestamp: 1650610691.0000 - _runtime: 1792.0000 - 74s/epoch - 78ms/step\n",
      "Epoch 24/200\n",
      "941/941 - 74s - loss: 0.0203 - mae: 0.0984 - val_loss: 0.1313 - val_mae: 0.2565 - _timestamp: 1650610765.0000 - _runtime: 1866.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 25/200\n",
      "941/941 - 75s - loss: 0.0222 - mae: 0.1019 - val_loss: 0.1152 - val_mae: 0.2094 - _timestamp: 1650610840.0000 - _runtime: 1941.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00026: val_mae improved from 0.20144 to 0.19746, saving model to callback/val_mae_00026_0.197455.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0199 - mae: 0.0971 - val_loss: 0.0878 - val_mae: 0.1975 - _timestamp: 1650610915.0000 - _runtime: 2016.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 27/200\n",
      "941/941 - 74s - loss: 0.0195 - mae: 0.0965 - val_loss: 0.0904 - val_mae: 0.1975 - _timestamp: 1650610989.0000 - _runtime: 2090.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00028: val_mae improved from 0.19746 to 0.18630, saving model to callback/val_mae_00028_0.186303.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0188 - mae: 0.0948 - val_loss: 0.0880 - val_mae: 0.1863 - _timestamp: 1650611063.0000 - _runtime: 2164.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 29/200\n",
      "941/941 - 74s - loss: 0.0265 - mae: 0.1115 - val_loss: 0.1031 - val_mae: 0.2105 - _timestamp: 1650611138.0000 - _runtime: 2239.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 30/200\n",
      "941/941 - 75s - loss: 0.0200 - mae: 0.0979 - val_loss: 0.0897 - val_mae: 0.2005 - _timestamp: 1650611213.0000 - _runtime: 2314.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 31/200\n",
      "941/941 - 75s - loss: 0.0184 - mae: 0.0936 - val_loss: 0.0876 - val_mae: 0.1976 - _timestamp: 1650611287.0000 - _runtime: 2388.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 32/200\n",
      "941/941 - 74s - loss: 0.0175 - mae: 0.0919 - val_loss: 0.0947 - val_mae: 0.1924 - _timestamp: 1650611362.0000 - _runtime: 2463.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 33/200\n",
      "941/941 - 74s - loss: 0.0181 - mae: 0.0932 - val_loss: 0.0807 - val_mae: 0.1998 - _timestamp: 1650611436.0000 - _runtime: 2537.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 34/200\n",
      "941/941 - 75s - loss: 0.0174 - mae: 0.0914 - val_loss: 0.0805 - val_mae: 0.1919 - _timestamp: 1650611511.0000 - _runtime: 2612.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00035: val_mae improved from 0.18630 to 0.17647, saving model to callback/val_mae_00035_0.176466.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0170 - mae: 0.0905 - val_loss: 0.0724 - val_mae: 0.1765 - _timestamp: 1650611585.0000 - _runtime: 2686.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 36/200\n",
      "941/941 - 74s - loss: 0.0168 - mae: 0.0901 - val_loss: 0.1056 - val_mae: 0.2090 - _timestamp: 1650611660.0000 - _runtime: 2761.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 37/200\n",
      "941/941 - 74s - loss: 0.0172 - mae: 0.0900 - val_loss: 0.0867 - val_mae: 0.2005 - _timestamp: 1650611734.0000 - _runtime: 2835.0000 - 74s/epoch - 78ms/step\n",
      "Epoch 38/200\n",
      "941/941 - 74s - loss: 0.0164 - mae: 0.0886 - val_loss: 0.1213 - val_mae: 0.2145 - _timestamp: 1650611809.0000 - _runtime: 2910.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 39/200\n",
      "941/941 - 74s - loss: 0.0163 - mae: 0.0888 - val_loss: 0.0888 - val_mae: 0.2033 - _timestamp: 1650611883.0000 - _runtime: 2984.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 40/200\n",
      "941/941 - 75s - loss: 0.0157 - mae: 0.0869 - val_loss: 0.0977 - val_mae: 0.2071 - _timestamp: 1650611957.0000 - _runtime: 3058.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 41/200\n",
      "941/941 - 74s - loss: 0.0201 - mae: 0.0923 - val_loss: 0.1272 - val_mae: 0.2533 - _timestamp: 1650612031.0000 - _runtime: 3132.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 42/200\n",
      "941/941 - 75s - loss: 0.0187 - mae: 0.0945 - val_loss: 0.0851 - val_mae: 0.2085 - _timestamp: 1650612106.0000 - _runtime: 3207.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 43/200\n",
      "941/941 - 74s - loss: 0.0156 - mae: 0.0863 - val_loss: 0.0862 - val_mae: 0.2011 - _timestamp: 1650612181.0000 - _runtime: 3282.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 44/200\n",
      "941/941 - 74s - loss: 0.0151 - mae: 0.0854 - val_loss: 0.0830 - val_mae: 0.1899 - _timestamp: 1650612255.0000 - _runtime: 3356.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 45/200\n",
      "941/941 - 75s - loss: 0.0146 - mae: 0.0843 - val_loss: 0.0878 - val_mae: 0.2082 - _timestamp: 1650612330.0000 - _runtime: 3431.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 46/200\n",
      "941/941 - 75s - loss: 0.0145 - mae: 0.0844 - val_loss: 0.0826 - val_mae: 0.1942 - _timestamp: 1650612404.0000 - _runtime: 3505.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 47/200\n",
      "941/941 - 75s - loss: 0.0142 - mae: 0.0832 - val_loss: 0.0787 - val_mae: 0.1925 - _timestamp: 1650612479.0000 - _runtime: 3580.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 48/200\n",
      "941/941 - 74s - loss: 0.0144 - mae: 0.0837 - val_loss: 0.1245 - val_mae: 0.2361 - _timestamp: 1650612553.0000 - _runtime: 3654.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 49/200\n",
      "941/941 - 75s - loss: 0.0137 - mae: 0.0822 - val_loss: 0.0990 - val_mae: 0.2380 - _timestamp: 1650612628.0000 - _runtime: 3729.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 50/200\n",
      "941/941 - 74s - loss: 0.1077 - mae: 0.1021 - val_loss: 0.0888 - val_mae: 0.2052 - _timestamp: 1650612702.0000 - _runtime: 3803.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 51/200\n",
      "941/941 - 75s - loss: 0.0161 - mae: 0.0882 - val_loss: 0.1043 - val_mae: 0.2276 - _timestamp: 1650612777.0000 - _runtime: 3878.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 52/200\n",
      "941/941 - 75s - loss: 0.0142 - mae: 0.0834 - val_loss: 0.1023 - val_mae: 0.1977 - _timestamp: 1650612852.0000 - _runtime: 3953.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 53/200\n",
      "941/941 - 75s - loss: 0.0135 - mae: 0.0813 - val_loss: 0.0931 - val_mae: 0.2125 - _timestamp: 1650612927.0000 - _runtime: 4028.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 54/200\n",
      "941/941 - 74s - loss: 0.0133 - mae: 0.0808 - val_loss: 0.0861 - val_mae: 0.1950 - _timestamp: 1650613001.0000 - _runtime: 4102.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 55/200\n",
      "941/941 - 75s - loss: 0.0134 - mae: 0.0811 - val_loss: 0.0900 - val_mae: 0.2022 - _timestamp: 1650613075.0000 - _runtime: 4176.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 56/200\n",
      "941/941 - 74s - loss: 0.0137 - mae: 0.0819 - val_loss: 0.0778 - val_mae: 0.1900 - _timestamp: 1650613150.0000 - _runtime: 4251.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 57/200\n",
      "941/941 - 75s - loss: 0.0133 - mae: 0.0806 - val_loss: 0.0877 - val_mae: 0.2073 - _timestamp: 1650613225.0000 - _runtime: 4326.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 58/200\n",
      "941/941 - 74s - loss: 0.0169 - mae: 0.0897 - val_loss: 0.1058 - val_mae: 0.2390 - _timestamp: 1650613299.0000 - _runtime: 4400.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 59/200\n",
      "941/941 - 75s - loss: 0.1173 - mae: 0.0915 - val_loss: 0.0979 - val_mae: 0.2256 - _timestamp: 1650613374.0000 - _runtime: 4475.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 60/200\n",
      "941/941 - 74s - loss: 0.0141 - mae: 0.0826 - val_loss: 0.0787 - val_mae: 0.1981 - _timestamp: 1650613449.0000 - _runtime: 4550.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 61/200\n",
      "941/941 - 75s - loss: 0.0131 - mae: 0.0799 - val_loss: 0.0941 - val_mae: 0.2068 - _timestamp: 1650613523.0000 - _runtime: 4624.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 62/200\n",
      "941/941 - 74s - loss: 0.0132 - mae: 0.0803 - val_loss: 0.0937 - val_mae: 0.2001 - _timestamp: 1650613598.0000 - _runtime: 4699.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 63/200\n",
      "941/941 - 75s - loss: 0.0132 - mae: 0.0804 - val_loss: 0.1086 - val_mae: 0.2221 - _timestamp: 1650613672.0000 - _runtime: 4773.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 64/200\n",
      "941/941 - 74s - loss: 0.0126 - mae: 0.0786 - val_loss: 0.0951 - val_mae: 0.1923 - _timestamp: 1650613747.0000 - _runtime: 4848.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 65/200\n",
      "941/941 - 75s - loss: 0.0124 - mae: 0.0778 - val_loss: 0.1112 - val_mae: 0.2238 - _timestamp: 1650613822.0000 - _runtime: 4923.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 66/200\n",
      "941/941 - 75s - loss: 0.0126 - mae: 0.0787 - val_loss: 0.0803 - val_mae: 0.2055 - _timestamp: 1650613897.0000 - _runtime: 4998.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 67/200\n",
      "941/941 - 75s - loss: 0.0124 - mae: 0.0779 - val_loss: 0.0869 - val_mae: 0.2032 - _timestamp: 1650613971.0000 - _runtime: 5072.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 68/200\n",
      "941/941 - 74s - loss: 0.0126 - mae: 0.0782 - val_loss: 0.0840 - val_mae: 0.2043 - _timestamp: 1650614045.0000 - _runtime: 5146.0000 - 74s/epoch - 78ms/step\n",
      "Epoch 69/200\n",
      "941/941 - 75s - loss: 0.0122 - mae: 0.0776 - val_loss: 0.0772 - val_mae: 0.1914 - _timestamp: 1650614120.0000 - _runtime: 5221.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 70/200\n",
      "941/941 - 75s - loss: 0.0121 - mae: 0.0768 - val_loss: 0.0910 - val_mae: 0.2138 - _timestamp: 1650614195.0000 - _runtime: 5296.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 71/200\n",
      "941/941 - 75s - loss: 0.0123 - mae: 0.0776 - val_loss: 0.0770 - val_mae: 0.1975 - _timestamp: 1650614270.0000 - _runtime: 5371.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 72/200\n",
      "941/941 - 74s - loss: 0.0123 - mae: 0.0778 - val_loss: 0.0763 - val_mae: 0.1869 - _timestamp: 1650614344.0000 - _runtime: 5445.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 73/200\n",
      "941/941 - 74s - loss: 0.0115 - mae: 0.0751 - val_loss: 0.1086 - val_mae: 0.2213 - _timestamp: 1650614418.0000 - _runtime: 5519.0000 - 74s/epoch - 78ms/step\n",
      "Epoch 74/200\n",
      "941/941 - 75s - loss: 0.0112 - mae: 0.0745 - val_loss: 0.0871 - val_mae: 0.2047 - _timestamp: 1650614493.0000 - _runtime: 5594.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 75/200\n",
      "941/941 - 74s - loss: 0.0116 - mae: 0.0755 - val_loss: 0.0726 - val_mae: 0.1882 - _timestamp: 1650614567.0000 - _runtime: 5668.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 76/200\n",
      "941/941 - 74s - loss: 0.0113 - mae: 0.0750 - val_loss: 0.0823 - val_mae: 0.2004 - _timestamp: 1650614641.0000 - _runtime: 5742.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 77/200\n",
      "941/941 - 74s - loss: 0.0125 - mae: 0.0779 - val_loss: 0.1039 - val_mae: 0.2247 - _timestamp: 1650614716.0000 - _runtime: 5817.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 78/200\n",
      "941/941 - 74s - loss: 0.0114 - mae: 0.0748 - val_loss: 0.1017 - val_mae: 0.2227 - _timestamp: 1650614790.0000 - _runtime: 5891.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 79/200\n",
      "941/941 - 75s - loss: 0.0109 - mae: 0.0737 - val_loss: 0.0875 - val_mae: 0.2068 - _timestamp: 1650614865.0000 - _runtime: 5966.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 80/200\n",
      "941/941 - 75s - loss: 0.0107 - mae: 0.0730 - val_loss: 0.0893 - val_mae: 0.2115 - _timestamp: 1650614940.0000 - _runtime: 6041.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 81/200\n",
      "941/941 - 75s - loss: 0.0114 - mae: 0.0748 - val_loss: 0.1258 - val_mae: 0.2372 - _timestamp: 1650615015.0000 - _runtime: 6116.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 82/200\n",
      "941/941 - 75s - loss: 0.0106 - mae: 0.0726 - val_loss: 0.0913 - val_mae: 0.2150 - _timestamp: 1650615090.0000 - _runtime: 6191.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 83/200\n",
      "941/941 - 75s - loss: 0.0107 - mae: 0.0729 - val_loss: 0.1024 - val_mae: 0.2213 - _timestamp: 1650615164.0000 - _runtime: 6265.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 84/200\n",
      "941/941 - 75s - loss: 0.0107 - mae: 0.0728 - val_loss: 0.0878 - val_mae: 0.2133 - _timestamp: 1650615239.0000 - _runtime: 6340.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 85/200\n",
      "941/941 - 75s - loss: 0.0115 - mae: 0.0754 - val_loss: 0.0877 - val_mae: 0.2061 - _timestamp: 1650615314.0000 - _runtime: 6415.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 86/200\n",
      "941/941 - 75s - loss: 0.0106 - mae: 0.0726 - val_loss: 0.0914 - val_mae: 0.1979 - _timestamp: 1650615389.0000 - _runtime: 6490.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 87/200\n",
      "941/941 - 75s - loss: 0.0100 - mae: 0.0710 - val_loss: 0.0799 - val_mae: 0.1903 - _timestamp: 1650615465.0000 - _runtime: 6566.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 88/200\n",
      "941/941 - 75s - loss: 0.0139 - mae: 0.0799 - val_loss: 0.0754 - val_mae: 0.1846 - _timestamp: 1650615540.0000 - _runtime: 6641.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 89/200\n",
      "941/941 - 75s - loss: 0.0112 - mae: 0.0743 - val_loss: 0.0769 - val_mae: 0.1894 - _timestamp: 1650615615.0000 - _runtime: 6716.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 90/200\n",
      "941/941 - 75s - loss: 0.0133 - mae: 0.0801 - val_loss: 0.0886 - val_mae: 0.2063 - _timestamp: 1650615689.0000 - _runtime: 6790.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 91/200\n",
      "941/941 - 75s - loss: 0.0112 - mae: 0.0740 - val_loss: 0.0873 - val_mae: 0.2094 - _timestamp: 1650615764.0000 - _runtime: 6865.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 92/200\n",
      "941/941 - 75s - loss: 0.0100 - mae: 0.0706 - val_loss: 0.0797 - val_mae: 0.2006 - _timestamp: 1650615839.0000 - _runtime: 6940.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 93/200\n",
      "941/941 - 75s - loss: 0.0113 - mae: 0.0744 - val_loss: 0.0719 - val_mae: 0.1822 - _timestamp: 1650615914.0000 - _runtime: 7015.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 94/200\n",
      "941/941 - 75s - loss: 0.0124 - mae: 0.0787 - val_loss: 0.0881 - val_mae: 0.2128 - _timestamp: 1650615989.0000 - _runtime: 7090.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 95/200\n",
      "941/941 - 74s - loss: 0.0114 - mae: 0.0753 - val_loss: 0.0885 - val_mae: 0.2097 - _timestamp: 1650616063.0000 - _runtime: 7164.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 96/200\n",
      "941/941 - 75s - loss: 0.0101 - mae: 0.0709 - val_loss: 0.0809 - val_mae: 0.2068 - _timestamp: 1650616138.0000 - _runtime: 7239.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 97/200\n",
      "941/941 - 75s - loss: 0.0098 - mae: 0.0704 - val_loss: 0.0833 - val_mae: 0.2042 - _timestamp: 1650616214.0000 - _runtime: 7315.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 98/200\n",
      "941/941 - 75s - loss: 0.0099 - mae: 0.0705 - val_loss: 0.1332 - val_mae: 0.2117 - _timestamp: 1650616288.0000 - _runtime: 7389.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 99/200\n",
      "941/941 - 74s - loss: 0.0115 - mae: 0.0749 - val_loss: 0.0745 - val_mae: 0.1908 - _timestamp: 1650616363.0000 - _runtime: 7464.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 100/200\n",
      "941/941 - 75s - loss: 0.0104 - mae: 0.0717 - val_loss: 0.0738 - val_mae: 0.1885 - _timestamp: 1650616438.0000 - _runtime: 7539.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 101/200\n",
      "941/941 - 75s - loss: 0.0108 - mae: 0.0731 - val_loss: 0.1037 - val_mae: 0.2098 - _timestamp: 1650616513.0000 - _runtime: 7614.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 102/200\n",
      "941/941 - 74s - loss: 0.0098 - mae: 0.0697 - val_loss: 0.0771 - val_mae: 0.1905 - _timestamp: 1650616587.0000 - _runtime: 7688.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 103/200\n",
      "941/941 - 75s - loss: 0.0096 - mae: 0.0694 - val_loss: 0.0699 - val_mae: 0.1861 - _timestamp: 1650616662.0000 - _runtime: 7763.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 104/200\n",
      "941/941 - 75s - loss: 0.0097 - mae: 0.0697 - val_loss: 0.0807 - val_mae: 0.2000 - _timestamp: 1650616737.0000 - _runtime: 7838.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 105/200\n",
      "941/941 - 75s - loss: 0.0098 - mae: 0.0699 - val_loss: 0.0686 - val_mae: 0.1970 - _timestamp: 1650616812.0000 - _runtime: 7913.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 106/200\n",
      "941/941 - 75s - loss: 0.0097 - mae: 0.0697 - val_loss: 0.0734 - val_mae: 0.1983 - _timestamp: 1650616886.0000 - _runtime: 7987.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 107/200\n",
      "941/941 - 75s - loss: 0.0098 - mae: 0.0700 - val_loss: 0.0771 - val_mae: 0.2007 - _timestamp: 1650616961.0000 - _runtime: 8062.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 108/200\n",
      "941/941 - 74s - loss: 0.0106 - mae: 0.0723 - val_loss: 0.0816 - val_mae: 0.2033 - _timestamp: 1650617036.0000 - _runtime: 8137.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 109/200\n",
      "941/941 - 75s - loss: 0.0095 - mae: 0.0689 - val_loss: 0.0755 - val_mae: 0.1958 - _timestamp: 1650617111.0000 - _runtime: 8212.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 110/200\n",
      "941/941 - 74s - loss: 0.0099 - mae: 0.0701 - val_loss: 0.0843 - val_mae: 0.1956 - _timestamp: 1650617185.0000 - _runtime: 8286.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 111/200\n",
      "941/941 - 75s - loss: 0.0093 - mae: 0.0682 - val_loss: 0.0769 - val_mae: 0.1875 - _timestamp: 1650617260.0000 - _runtime: 8361.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 112/200\n",
      "941/941 - 74s - loss: 0.0091 - mae: 0.0677 - val_loss: 0.0749 - val_mae: 0.2018 - _timestamp: 1650617335.0000 - _runtime: 8436.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 113/200\n",
      "941/941 - 75s - loss: 0.0091 - mae: 0.0678 - val_loss: 0.0767 - val_mae: 0.1996 - _timestamp: 1650617410.0000 - _runtime: 8511.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 114/200\n",
      "941/941 - 74s - loss: 0.0092 - mae: 0.0680 - val_loss: 0.0813 - val_mae: 0.1888 - _timestamp: 1650617484.0000 - _runtime: 8585.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 115/200\n",
      "941/941 - 75s - loss: 0.0092 - mae: 0.0680 - val_loss: 0.0891 - val_mae: 0.2150 - _timestamp: 1650617559.0000 - _runtime: 8660.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 116/200\n",
      "941/941 - 74s - loss: 0.0090 - mae: 0.0671 - val_loss: 0.0719 - val_mae: 0.1828 - _timestamp: 1650617633.0000 - _runtime: 8734.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 117/200\n",
      "941/941 - 74s - loss: 0.0092 - mae: 0.0680 - val_loss: 0.0824 - val_mae: 0.2017 - _timestamp: 1650617708.0000 - _runtime: 8809.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 118/200\n",
      "941/941 - 74s - loss: 0.0096 - mae: 0.0692 - val_loss: 0.0741 - val_mae: 0.1924 - _timestamp: 1650617782.0000 - _runtime: 8883.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 119/200\n",
      "941/941 - 75s - loss: 0.0089 - mae: 0.0668 - val_loss: 0.1006 - val_mae: 0.2005 - _timestamp: 1650617857.0000 - _runtime: 8958.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 120/200\n",
      "941/941 - 75s - loss: 0.0087 - mae: 0.0662 - val_loss: 0.0802 - val_mae: 0.1917 - _timestamp: 1650617933.0000 - _runtime: 9034.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 121/200\n",
      "941/941 - 75s - loss: 0.0085 - mae: 0.0658 - val_loss: 0.0743 - val_mae: 0.1882 - _timestamp: 1650618007.0000 - _runtime: 9108.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0089 - mae: 0.0666 - val_loss: 0.0875 - val_mae: 0.2171 - _timestamp: 1650618082.0000 - _runtime: 9183.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00123: val_mae improved from 0.17647 to 0.17639, saving model to callback/val_mae_00123_0.176395.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 76s - loss: 0.0092 - mae: 0.0678 - val_loss: 0.0669 - val_mae: 0.1764 - _timestamp: 1650618158.0000 - _runtime: 9259.0000 - 76s/epoch - 81ms/step\n",
      "Epoch 124/200\n",
      "941/941 - 75s - loss: 0.0088 - mae: 0.0665 - val_loss: 0.0919 - val_mae: 0.1996 - _timestamp: 1650618234.0000 - _runtime: 9335.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 125/200\n",
      "941/941 - 75s - loss: 0.0084 - mae: 0.0656 - val_loss: 0.0773 - val_mae: 0.2022 - _timestamp: 1650618309.0000 - _runtime: 9410.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 126/200\n",
      "941/941 - 75s - loss: 0.0099 - mae: 0.0698 - val_loss: 0.0803 - val_mae: 0.2128 - _timestamp: 1650618384.0000 - _runtime: 9485.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 127/200\n",
      "941/941 - 74s - loss: 0.0087 - mae: 0.0660 - val_loss: 0.0963 - val_mae: 0.2104 - _timestamp: 1650618458.0000 - _runtime: 9559.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 128/200\n",
      "941/941 - 75s - loss: 0.0086 - mae: 0.0658 - val_loss: 0.0745 - val_mae: 0.1954 - _timestamp: 1650618533.0000 - _runtime: 9634.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 129/200\n",
      "941/941 - 75s - loss: 0.0083 - mae: 0.0647 - val_loss: 0.0750 - val_mae: 0.1923 - _timestamp: 1650618608.0000 - _runtime: 9709.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 130/200\n",
      "941/941 - 75s - loss: 0.0083 - mae: 0.0650 - val_loss: 0.0947 - val_mae: 0.2116 - _timestamp: 1650618683.0000 - _runtime: 9784.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 131/200\n",
      "941/941 - 74s - loss: 0.0088 - mae: 0.0665 - val_loss: 0.0889 - val_mae: 0.1996 - _timestamp: 1650618757.0000 - _runtime: 9858.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 132/200\n",
      "941/941 - 75s - loss: 0.0094 - mae: 0.0685 - val_loss: 0.0806 - val_mae: 0.1890 - _timestamp: 1650618832.0000 - _runtime: 9933.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 133/200\n",
      "941/941 - 75s - loss: 0.0085 - mae: 0.0654 - val_loss: 0.0815 - val_mae: 0.2031 - _timestamp: 1650618907.0000 - _runtime: 10008.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 134/200\n",
      "941/941 - 75s - loss: 0.0096 - mae: 0.0687 - val_loss: 0.0760 - val_mae: 0.1930 - _timestamp: 1650618982.0000 - _runtime: 10083.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 135/200\n",
      "941/941 - 74s - loss: 0.0088 - mae: 0.0661 - val_loss: 0.0873 - val_mae: 0.2052 - _timestamp: 1650619056.0000 - _runtime: 10157.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 136/200\n",
      "941/941 - 75s - loss: 0.0082 - mae: 0.0642 - val_loss: 0.0872 - val_mae: 0.2023 - _timestamp: 1650619131.0000 - _runtime: 10232.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 137/200\n",
      "941/941 - 75s - loss: 0.0097 - mae: 0.0691 - val_loss: 0.1550 - val_mae: 0.2854 - _timestamp: 1650619205.0000 - _runtime: 10306.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 138/200\n",
      "941/941 - 75s - loss: 0.0092 - mae: 0.0671 - val_loss: 0.0872 - val_mae: 0.2178 - _timestamp: 1650619280.0000 - _runtime: 10381.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 139/200\n",
      "941/941 - 75s - loss: 0.0093 - mae: 0.0673 - val_loss: 0.0772 - val_mae: 0.1849 - _timestamp: 1650619355.0000 - _runtime: 10456.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00140: val_mae improved from 0.17639 to 0.17439, saving model to callback/val_mae_00140_0.174394.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 76s - loss: 0.0330 - mae: 0.0783 - val_loss: 0.0658 - val_mae: 0.1744 - _timestamp: 1650619430.0000 - _runtime: 10531.0000 - 76s/epoch - 80ms/step\n",
      "Epoch 141/200\n",
      "941/941 - 75s - loss: 0.0091 - mae: 0.0673 - val_loss: 0.0809 - val_mae: 0.2073 - _timestamp: 1650619506.0000 - _runtime: 10607.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 142/200\n",
      "941/941 - 75s - loss: 0.0081 - mae: 0.0641 - val_loss: 0.0839 - val_mae: 0.2017 - _timestamp: 1650619580.0000 - _runtime: 10681.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 143/200\n",
      "941/941 - 75s - loss: 0.0081 - mae: 0.0639 - val_loss: 0.0978 - val_mae: 0.2179 - _timestamp: 1650619655.0000 - _runtime: 10756.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 144/200\n",
      "941/941 - 75s - loss: 0.0082 - mae: 0.0642 - val_loss: 0.0877 - val_mae: 0.2053 - _timestamp: 1650619730.0000 - _runtime: 10831.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:\n",
      "Epoch 00145: val_mae improved from 0.17439 to 0.17271, saving model to callback/val_mae_00145_0.172709.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 75s - loss: 0.0081 - mae: 0.0640 - val_loss: 0.0666 - val_mae: 0.1727 - _timestamp: 1650619805.0000 - _runtime: 10906.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 146/200\n",
      "941/941 - 75s - loss: 0.0080 - mae: 0.0636 - val_loss: 0.1036 - val_mae: 0.2096 - _timestamp: 1650619880.0000 - _runtime: 10981.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 147/200\n",
      "941/941 - 75s - loss: 0.0078 - mae: 0.0632 - val_loss: 0.0928 - val_mae: 0.2076 - _timestamp: 1650619955.0000 - _runtime: 11056.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 148/200\n",
      "941/941 - 75s - loss: 0.0085 - mae: 0.0655 - val_loss: 0.1020 - val_mae: 0.2031 - _timestamp: 1650620030.0000 - _runtime: 11131.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 149/200\n",
      "941/941 - 75s - loss: 0.0089 - mae: 0.0665 - val_loss: 0.0900 - val_mae: 0.2067 - _timestamp: 1650620105.0000 - _runtime: 11206.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 150/200\n",
      "941/941 - 75s - loss: 0.0079 - mae: 0.0632 - val_loss: 0.0845 - val_mae: 0.2025 - _timestamp: 1650620180.0000 - _runtime: 11281.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 151/200\n",
      "941/941 - 75s - loss: 0.0077 - mae: 0.0626 - val_loss: 0.0953 - val_mae: 0.2165 - _timestamp: 1650620255.0000 - _runtime: 11356.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 152/200\n",
      "941/941 - 75s - loss: 0.0088 - mae: 0.0664 - val_loss: 0.0799 - val_mae: 0.1930 - _timestamp: 1650620330.0000 - _runtime: 11431.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 153/200\n",
      "941/941 - 74s - loss: 0.0106 - mae: 0.0708 - val_loss: 0.1102 - val_mae: 0.2279 - _timestamp: 1650620404.0000 - _runtime: 11505.0000 - 74s/epoch - 79ms/step\n",
      "Epoch 154/200\n",
      "941/941 - 75s - loss: 0.0102 - mae: 0.0701 - val_loss: 0.0782 - val_mae: 0.1949 - _timestamp: 1650620479.0000 - _runtime: 11580.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 155/200\n",
      "941/941 - 75s - loss: 0.0079 - mae: 0.0631 - val_loss: 0.0837 - val_mae: 0.2026 - _timestamp: 1650620555.0000 - _runtime: 11656.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 156/200\n",
      "941/941 - 75s - loss: 0.0078 - mae: 0.0628 - val_loss: 0.0679 - val_mae: 0.1854 - _timestamp: 1650620629.0000 - _runtime: 11730.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 157/200\n",
      "941/941 - 75s - loss: 0.0076 - mae: 0.0624 - val_loss: 0.0808 - val_mae: 0.1868 - _timestamp: 1650620704.0000 - _runtime: 11805.0000 - 75s/epoch - 79ms/step\n",
      "Epoch 158/200\n",
      "941/941 - 75s - loss: 0.0079 - mae: 0.0633 - val_loss: 0.1147 - val_mae: 0.2359 - _timestamp: 1650620779.0000 - _runtime: 11880.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 159/200\n",
      "941/941 - 75s - loss: 0.0088 - mae: 0.0666 - val_loss: 0.0970 - val_mae: 0.2207 - _timestamp: 1650620854.0000 - _runtime: 11955.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 160/200\n",
      "941/941 - 75s - loss: 0.0079 - mae: 0.0633 - val_loss: 0.0738 - val_mae: 0.1983 - _timestamp: 1650620929.0000 - _runtime: 12030.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 161/200\n",
      "941/941 - 75s - loss: 0.0077 - mae: 0.0626 - val_loss: 0.0913 - val_mae: 0.2103 - _timestamp: 1650621005.0000 - _runtime: 12106.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 162/200\n",
      "941/941 - 75s - loss: 0.0217 - mae: 0.0751 - val_loss: 0.0915 - val_mae: 0.2145 - _timestamp: 1650621080.0000 - _runtime: 12181.0000 - 75s/epoch - 80ms/step\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:Load weights ./callback/val_mae_00145_0.172709.hdf5\n",
      "INFO:megnet.callbacks:Loss shot up from 0.022 to 6.266! Reducing lr \n",
      "INFO:megnet.callbacks:Now lr is 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/941 - 78s - loss: 6.2665 - mae: 0.1108 - val_loss: 0.0887 - val_mae: 0.2105 - _timestamp: 1650621155.0000 - _runtime: 12256.0000 - 78s/epoch - 83ms/step\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m wandb_memo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m wandb_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal models\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mrunning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_on\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_memo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/4.BRL/12.MEGNET/MEGNET/megnet_custom/run.py:142\u001b[0m, in \u001b[0;36mtrainer.train\u001b[0;34m(self, epochs, lr, batch_size, dropout, wandb_on, wandb_project, wandb_name, wandb_memo, wandb_group)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m''' training '''\u001b[39;00m\n\u001b[1;32m    141\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m epochs\n\u001b[0;32m--> 142\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_from_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/4.BRL/12.MEGNET/MEGNET/megnet_custom/megnet/models/base.py:227\u001b[0m, in \u001b[0;36mGraphModel.train_from_graphs\u001b[0;34m(self, train_graphs, train_targets, validation_graphs, validation_targets, sample_weights, epochs, batch_size, verbose, callbacks, prev_model, lr_scaling_factor, patience, save_checkpoint, automatic_correction, dirname, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generator(\u001b[38;5;241m*\u001b[39mtrain_inputs, sample_weights\u001b[38;5;241m=\u001b[39msample_weights, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m    226\u001b[0m steps_per_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(train_graphs) \u001b[38;5;241m/\u001b[39m batch_size))\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/0.File/anaconda3/envs/megnet/lib/python3.9/site-packages/wandb/integration/keras/keras.py:168\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    167\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/0.File/anaconda3/envs/megnet/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/0.File/anaconda3/envs/megnet/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "''' running setting '''\n",
    "epochs=200\n",
    "lr=0.001\n",
    "batch_size=16\n",
    "dropout=0.1\n",
    "\n",
    "''' wandb setting '''\n",
    "wandb_on=True\n",
    "wandb_project='MEGNET_feature_test'\n",
    "wandb_name='full_data_with_rdkit_float'\n",
    "wandb_memo='real model'\n",
    "wandb_group='final models'\n",
    "\n",
    "running.train(epochs, lr, batch_size, dropout, wandb_on, wandb_project, wandb_name, wandb_memo, wandb_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126480d2-55ad-4b9f-ae3c-485d7c5b2837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megnet",
   "language": "python",
   "name": "megnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
